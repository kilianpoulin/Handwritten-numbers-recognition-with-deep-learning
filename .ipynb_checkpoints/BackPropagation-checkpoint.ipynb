{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network architecture**</font>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Variable</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OUTPUTS</td>\n",
    "        <td><i>array containing all possible outputs</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_HIDDEN_LAYERS</td>\n",
    "        <td><i>integer</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_HIDDEN_NODES</td>\n",
    "        <td><i>array containing the number of hidden nodes for each hidden layer (from the first one to the last one)</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_INPUTS </td>\n",
    "        <td><i>number of nodes on the input layer</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_EPOCH </td>\n",
    "        <td><i>number of times the training data set will be used entirely to train the network</i></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "OUTPUTS = [0, 2, 4, 6, 8]\n",
    "NB_OUTPUTS = len(OUTPUTS)\n",
    "NB_HIDDEN_LAYERS = 1\n",
    "NB_HIDDEN_NODES = [100]\n",
    "NB_INPUTS = 784\n",
    "NB_EPOCH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural Network Training settings**</font>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center\">Variable</th>\n",
    "        <th style=\"text-align: center\">Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Training dataset</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_DATA</td>\n",
    "        <td style=\"text-align: left\"><i>integer - Number of data used in the dataset</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>TRAINING PATH</td>\n",
    "        <td style=\"text-align: left\"><i>string - relative or full path of the training dataset folder</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DATA_TYPE</td>\n",
    "        <td style=\"text-align: left\"><i>string - either 'img' or 'xor', depends on type of input data</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Learning rate</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L_RATE</td>\n",
    "        <td style=\"text-align: left\"><i>float - Initial learning rate for the first epoch</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L_RATE_DESC</td>\n",
    "        <td style=\"text-align: left\"><i>float - variation of the learning rate : L_RATE * L_RATE_DESC at the end of each epoch. If no variation then L_RATE_DESC = 1.0</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Weights</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center\">WEIGHTS_LOW_BOUND</td>\n",
    "        <td style=\"text-align: left\"><i>float or integer - Weights are initialized randomly in a range of values</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>WEIGHTS_HIGH_BOUND</td>\n",
    "        <td style=\"text-align: left\"><i>float or integer - Weights are initialized randomly in a range of values</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Error</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>ERR_THRESHOLD</td>\n",
    "        <td style=\"text-align: left\"><i>Minimum limit for the error value. If reached, the network can stop learning. Accuracy is good enough</i></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DATA = 16000\n",
    "TRAINING_PATH = 'Training data/'\n",
    "DATA_TYPE = 'img'\n",
    "\n",
    "# LEARNING RATE\n",
    "L_RATE = 0.01\n",
    "L_RATE_DESC = 1.0\n",
    "\n",
    "# INITIAL WEIGHTS RANGE\n",
    "WEIGHTS_LOW_BOUND = -0.5\n",
    "WEIGHTS_HIGH_BOUND = 0.5\n",
    "\n",
    "# ERROR THRESHOLD\n",
    "ERR_THRESHOLD = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Load dataset**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadImage(img_path, number = 0):\n",
    "    pix = np.asarray(Image.open(img_path).convert('L'))\n",
    "    pix = ((pix * (1 / 2550) - 0.05)).reshape(784)\n",
    "    expected = []\n",
    "    if OUTPUTS != []:\n",
    "        for i in OUTPUTS:\n",
    "            if i == number:\n",
    "                expected = np.append(expected, 1)\n",
    "            else:\n",
    "                expected = np.append(expected, 0)\n",
    "    return pix, expected\n",
    "\n",
    "def printImage(img_path):\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((12, 12), Image.ANTIALIAS)\n",
    "    print(img)\n",
    "    #plt.imshow(img)\n",
    "    plt.pause(1)\n",
    "    \n",
    "def load_training_dataset():\n",
    "    dataset = []\n",
    "    expected = []\n",
    "    \n",
    "    filenames = []\n",
    "    for o in OUTPUTS:\n",
    "        for filename in glob.glob(TRAINING_PATH + str(o) + '/*.png'): \n",
    "            base = os.path.basename(filename)\n",
    "            filenames.append([str(o) + '/' + base, o])\n",
    "    \n",
    "    random.shuffle(filenames)\n",
    "    if NB_DATA != 0:\n",
    "        filenames = filenames[:NB_DATA]\n",
    "        \n",
    "    for file in filenames:\n",
    "        img, exp = loadImage(TRAINING_PATH + file[0], file[1])\n",
    "        dataset.append(img)\n",
    "        expected.append(exp)\n",
    "        \n",
    "    return dataset, expected\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = []\n",
    "    filenames = []\n",
    "    for filename in glob.glob(path + '/*.png'): \n",
    "        dataset.append(loadImage(filename))\n",
    "        base = os.path.splitext(os.path.basename(filename))[0]\n",
    "        filenames.append(base)\n",
    "     \n",
    "    return len(dataset), filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Initialization**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network():\n",
    "    \n",
    "    global network\n",
    "    w = []\n",
    "    \n",
    "    # additionnal hidden layers\n",
    "    for i in range(NB_HIDDEN_LAYERS):\n",
    "        neurons = [{ 'neurons': NB_HIDDEN_NODES[i]}]\n",
    "        if i == 0:\n",
    "            w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_HIDDEN_NODES[i], NB_INPUTS)))\n",
    "        else:\n",
    "            w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_HIDDEN_NODES[i], NB_HIDDEN_NODES[i - 1])))\n",
    "\n",
    "        network.append(neurons)\n",
    "    \n",
    "    # output layer\n",
    "    neurons = [{ 'neurons': NB_OUTPUTS}]\n",
    "    w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_OUTPUTS, NB_HIDDEN_NODES[NB_HIDDEN_LAYERS - 1])))\n",
    "    network.append(neurons)\n",
    "    \n",
    "    for layer in network:\n",
    "              \n",
    "        wTmp = {'w': w[0]}\n",
    "        layer.append(wTmp)\n",
    "        w.pop(0)\n",
    "        \n",
    "        aTmp = { 'a': np.matrix(np.random.rand(layer[0]['neurons']))}\n",
    "        layer.append(aTmp)\n",
    "        \n",
    "        eTmp = { 'e': np.matrix(np.random.rand(layer[0]['neurons']))}\n",
    "        layer.append(eTmp)\n",
    "        \n",
    "    print('end initializing network')\n",
    "    return network\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Deep Learning - Forward Propagation**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    " \n",
    "def forward_prop(inputs):\n",
    "    global network\n",
    "    vect_sigmoid = np.vectorize(sigmoid)\n",
    "    \n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        new_inputs = []\n",
    "        \n",
    "        if (inputs.shape)[0] == 1 :\n",
    "            layer[0]['a'] = vect_sigmoid(np.dot(layer[1]['w'], inputs.T))\n",
    "        else:\n",
    "            layer[0]['a'] = vect_sigmoid(np.dot(layer[1]['w'], inputs))\n",
    "\n",
    "        new_inputs.append(layer[0]['a'])\n",
    "        inputs = new_inputs[0]\n",
    "    return np.matrix(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Deep Learning - Backpropagation error**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(data):\n",
    "    delta = []\n",
    "    global L_RATE\n",
    "    \n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        \n",
    "        if i != 0:\n",
    "            delta = np.multiply((layer[3]['e'] * L_RATE).T, network[i - 1][0]['a'])\n",
    "        else:\n",
    "            delta = np.multiply((layer[3]['e'] * L_RATE).T, data)\n",
    "        layer[1]['w'] = layer[1]['w'] + delta.T\n",
    "        \n",
    "def backward_prop_error(expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = []\n",
    "        \n",
    "        # case where it is not the output layer\n",
    "        if i != len(network)-1:\n",
    "            o_errors = network[i + 1][3]['e']\n",
    "            o_weights = network[i + 1][1]['w']\n",
    "            \n",
    "            errors = np.dot(\n",
    "                np.dot(o_weights.T, o_errors),\n",
    "                np.dot((layer[0]['a'].T), 1 - layer[0]['a']))\n",
    "            \n",
    "            layer[3]['e'] = errors\n",
    "        else:\n",
    "            errors = np.dot(expected.T - layer[0]['a'], np.dot((layer[0]['a']).T, (1 - layer[0]['a'])))\n",
    "            layer[3]['e']  = errors\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Training**</font>\n",
    "<br><br>\n",
    "\n",
    "* **train_network()**\n",
    "<br>\n",
    "Executes the whole training process (forward propagation + backward propagation error + updating weights) for each epoch\n",
    "<br><br>\n",
    "\n",
    "* **error_function**(expected outputs: array of integers, outputs of the program: array of floats)\n",
    "<br>\n",
    "Calculates the average error for each output when processing element thru the neural network\n",
    "<br><br>\n",
    "\n",
    "* **update_line**(plot: plt, new error value: integer, iter: integer)\n",
    "<br>\n",
    "Adds the newly calculated error to the graph showing evolution of the error function values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_function(expected, outputs):\n",
    "   # return (1/len(outputs)) * sum(np.square(expected - outputs))\n",
    "    return sum(np.square(expected - outputs))\n",
    "\n",
    "def update_line(hl, new_data, iter):\n",
    "    hl.set_xdata(np.append(hl.get_xdata(), iter))\n",
    "    hl.set_ydata(np.append(hl.get_ydata(), new_data))\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "def train_network():\n",
    "    \n",
    "    global network\n",
    "    global L_RATE\n",
    "    global L_RATE_DESC\n",
    "    expected = []\n",
    "    dataset = []\n",
    "    \n",
    "    \n",
    "    # ------ Initialization part -------\n",
    "    \n",
    "    if data_type == 'img':\n",
    "        if dataset == []:\n",
    "            dataset, exp = load_training_dataset()\n",
    "            x = np.matrix(dataset)\n",
    "            expected = np.matrix(exp)\n",
    "        else:\n",
    "            x = dataset\n",
    "    elif data_type == 'xor':\n",
    "        x = np.matrix([[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]])\n",
    "    else:\n",
    "        return 'Wrong datatype (should be iprintpmg or xor)'\n",
    "\n",
    "    network = initialize_network()\n",
    "    \n",
    "    \n",
    "    # --------- Training part ----------\n",
    "    \n",
    "    err_plot, = plt.plot([], [])\n",
    "    plt.ylabel('error')\n",
    "    axes = plt.gca()\n",
    "    iter = 0\n",
    "    \n",
    "    for epoch in range(NB_EPOCH):\n",
    "        error = 0\n",
    "        iter = 0\n",
    "        for data in train:\n",
    "            new_data = data.T\n",
    "            outputs = forward_prop(new_data)\n",
    "            \n",
    "            error += error_function(expected[iter].T, outputs)\n",
    "            \n",
    "            backward_prop_error(expected[iter])\n",
    "            update_weights(new_data)\n",
    "            \n",
    "            iter += 1\n",
    "            \n",
    "        final_err = error / len(train)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, L_RATE, final_err))\n",
    "        \n",
    "        L_RATE *= L_RATE_DESC\n",
    "        if epoch == 0:\n",
    "            axes.set_xlim([0, NB_EPOCH - 1])\n",
    "            axes.set_ylim([0, float(final_err) + 0.1])\n",
    "            \n",
    "        update_line(err_plot, final_err, epoch)\n",
    "        \n",
    "        if error < ERR_THRESHOLD:\n",
    "            print('error : ' + str(final_err))\n",
    "            return network\n",
    "    print('error     : ' + str(final_err))\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Additional training**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(data_type, data_nb, nb_iter = 0, outputs = []):\n",
    "\n",
    "    nb_outputs = 0\n",
    "    nb_inputs = 0\n",
    "    \n",
    "    #for images\n",
    "    if data_type == 'img':\n",
    "        nb_inputs = 28 * 28\n",
    "        \n",
    "        \n",
    "        \n",
    "        nb_outputs = len(outputs)\n",
    "        x = np.array(load_training_dataset(outputs, data_nb), dtype=np.dtype(Decimal))\n",
    "        x = [[ Decimal(i) for i in j] for j in x]\n",
    "    elif data_type == 'xor':\n",
    "        nb_outputs = 3\n",
    "        nb_inputs = 2\n",
    "        x = [[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]]\n",
    "    else:\n",
    "        return 'Wrong datatype (should be img or xor)'\n",
    "\n",
    "\n",
    "    return train_network(network, x, 1, nb_outputs, nb_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Execution - Training**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end loading dataset\n",
      "end initializing network\n",
      "l rate = 0.01\n",
      ">epoch=0, lrate=0.010, error=0.160\n",
      ">epoch=1, lrate=0.010, error=0.104\n",
      ">epoch=2, lrate=0.010, error=0.094\n",
      ">epoch=3, lrate=0.010, error=0.088\n",
      ">epoch=4, lrate=0.010, error=0.084\n",
      "error     : [[0.08369018]]\n",
      "correct : 3822 (95.55 %)\n",
      "wrong : 178 (4.45 %)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[0, 4, 'Testing data/0\\\\3210.png'],\n",
       " [0, 8, 'Testing data/0\\\\3469.png'],\n",
       " [0, 8, 'Testing data/0\\\\3592.png'],\n",
       " [0, 2, 'Testing data/0\\\\3609.png'],\n",
       " [0, 2, 'Testing data/0\\\\3653.png'],\n",
       " [0, 4, 'Testing data/0\\\\3681.png'],\n",
       " [0, 8, 'Testing data/0\\\\3697.png'],\n",
       " [0, 8, 'Testing data/0\\\\3828.png'],\n",
       " [0, 8, 'Testing data/0\\\\3919.png'],\n",
       " [0, 6, 'Testing data/0\\\\3930.png'],\n",
       " [0, 6, 'Testing data/0\\\\3950.png'],\n",
       " [0, 6, 'Testing data/0\\\\3956.png'],\n",
       " [2, 0, 'Testing data/2\\\\3224.png'],\n",
       " [2, 4, 'Testing data/2\\\\3226.png'],\n",
       " [2, 4, 'Testing data/2\\\\3230.png'],\n",
       " [2, 0, 'Testing data/2\\\\3272.png'],\n",
       " [2, 0, 'Testing data/2\\\\3342.png'],\n",
       " [2, 6, 'Testing data/2\\\\3345.png'],\n",
       " [2, 6, 'Testing data/2\\\\3390.png'],\n",
       " [2, 4, 'Testing data/2\\\\3447.png'],\n",
       " [2, 4, 'Testing data/2\\\\3454.png'],\n",
       " [2, 4, 'Testing data/2\\\\3492.png'],\n",
       " [2, 4, 'Testing data/2\\\\3498.png'],\n",
       " [2, 4, 'Testing data/2\\\\3502.png'],\n",
       " [2, 6, 'Testing data/2\\\\3511.png'],\n",
       " [2, 0, 'Testing data/2\\\\3566.png'],\n",
       " [2, 0, 'Testing data/2\\\\3570.png'],\n",
       " [2, 8, 'Testing data/2\\\\3580.png'],\n",
       " [2, 4, 'Testing data/2\\\\3584.png'],\n",
       " [2, 0, 'Testing data/2\\\\3653.png'],\n",
       " [2, 6, 'Testing data/2\\\\3717.png'],\n",
       " [2, 0, 'Testing data/2\\\\3736.png'],\n",
       " [2, 6, 'Testing data/2\\\\3751.png'],\n",
       " [2, 6, 'Testing data/2\\\\3795.png'],\n",
       " [2, 6, 'Testing data/2\\\\3798.png'],\n",
       " [2, 0, 'Testing data/2\\\\3800.png'],\n",
       " [2, 0, 'Testing data/2\\\\3834.png'],\n",
       " [2, 0, 'Testing data/2\\\\3855.png'],\n",
       " [2, 0, 'Testing data/2\\\\3857.png'],\n",
       " [2, 0, 'Testing data/2\\\\3859.png'],\n",
       " [2, 8, 'Testing data/2\\\\3864.png'],\n",
       " [2, 8, 'Testing data/2\\\\3868.png'],\n",
       " [2, 8, 'Testing data/2\\\\3871.png'],\n",
       " [2, 6, 'Testing data/2\\\\3874.png'],\n",
       " [2, 6, 'Testing data/2\\\\3886.png'],\n",
       " [2, 8, 'Testing data/2\\\\3892.png'],\n",
       " [2, 4, 'Testing data/2\\\\3920.png'],\n",
       " [2, 4, 'Testing data/2\\\\3922.png'],\n",
       " [2, 4, 'Testing data/2\\\\3924.png'],\n",
       " [2, 8, 'Testing data/2\\\\3927.png'],\n",
       " [2, 6, 'Testing data/2\\\\3971.png'],\n",
       " [4, 2, 'Testing data/4\\\\3245.png'],\n",
       " [4, 8, 'Testing data/4\\\\3305.png'],\n",
       " [4, 8, 'Testing data/4\\\\3308.png'],\n",
       " [4, 8, 'Testing data/4\\\\3318.png'],\n",
       " [4, 6, 'Testing data/4\\\\3369.png'],\n",
       " [4, 2, 'Testing data/4\\\\3375.png'],\n",
       " [4, 6, 'Testing data/4\\\\3381.png'],\n",
       " [4, 8, 'Testing data/4\\\\3386.png'],\n",
       " [4, 0, 'Testing data/4\\\\3445.png'],\n",
       " [4, 6, 'Testing data/4\\\\3562.png'],\n",
       " [4, 6, 'Testing data/4\\\\3581.png'],\n",
       " [4, 2, 'Testing data/4\\\\3585.png'],\n",
       " [4, 6, 'Testing data/4\\\\3603.png'],\n",
       " [4, 2, 'Testing data/4\\\\3620.png'],\n",
       " [4, 8, 'Testing data/4\\\\3660.png'],\n",
       " [4, 2, 'Testing data/4\\\\3662.png'],\n",
       " [4, 8, 'Testing data/4\\\\3718.png'],\n",
       " [4, 6, 'Testing data/4\\\\3757.png'],\n",
       " [4, 8, 'Testing data/4\\\\3765.png'],\n",
       " [4, 8, 'Testing data/4\\\\3773.png'],\n",
       " [4, 2, 'Testing data/4\\\\3794.png'],\n",
       " [4, 0, 'Testing data/4\\\\3829.png'],\n",
       " [4, 2, 'Testing data/4\\\\3873.png'],\n",
       " [4, 2, 'Testing data/4\\\\3876.png'],\n",
       " [4, 8, 'Testing data/4\\\\3933.png'],\n",
       " [4, 8, 'Testing data/4\\\\3935.png'],\n",
       " [4, 2, 'Testing data/4\\\\3941.png'],\n",
       " [4, 2, 'Testing data/4\\\\3984.png'],\n",
       " [6, 2, 'Testing data/6\\\\3281.png'],\n",
       " [6, 2, 'Testing data/6\\\\3318.png'],\n",
       " [6, 4, 'Testing data/6\\\\3367.png'],\n",
       " [6, 4, 'Testing data/6\\\\3368.png'],\n",
       " [6, 2, 'Testing data/6\\\\3453.png'],\n",
       " [6, 2, 'Testing data/6\\\\3478.png'],\n",
       " [6, 2, 'Testing data/6\\\\3491.png'],\n",
       " [6, 0, 'Testing data/6\\\\3518.png'],\n",
       " [6, 2, 'Testing data/6\\\\3525.png'],\n",
       " [6, 2, 'Testing data/6\\\\3551.png'],\n",
       " [6, 0, 'Testing data/6\\\\3568.png'],\n",
       " [6, 2, 'Testing data/6\\\\3600.png'],\n",
       " [6, 2, 'Testing data/6\\\\3608.png'],\n",
       " [6, 2, 'Testing data/6\\\\3675.png'],\n",
       " [6, 0, 'Testing data/6\\\\3677.png'],\n",
       " [6, 8, 'Testing data/6\\\\3685.png'],\n",
       " [6, 0, 'Testing data/6\\\\3746.png'],\n",
       " [6, 0, 'Testing data/6\\\\3750.png'],\n",
       " [6, 0, 'Testing data/6\\\\3791.png'],\n",
       " [6, 0, 'Testing data/6\\\\3820.png'],\n",
       " [6, 4, 'Testing data/6\\\\3872.png'],\n",
       " [6, 4, 'Testing data/6\\\\3916.png'],\n",
       " [6, 4, 'Testing data/6\\\\3947.png'],\n",
       " [6, 2, 'Testing data/6\\\\3994.png'],\n",
       " [6, 2, 'Testing data/6\\\\3997.png'],\n",
       " [8, 2, 'Testing data/8\\\\3204.png'],\n",
       " [8, 2, 'Testing data/8\\\\3216.png'],\n",
       " [8, 2, 'Testing data/8\\\\3223.png'],\n",
       " [8, 4, 'Testing data/8\\\\3225.png'],\n",
       " [8, 2, 'Testing data/8\\\\3247.png'],\n",
       " [8, 4, 'Testing data/8\\\\3261.png'],\n",
       " [8, 0, 'Testing data/8\\\\3283.png'],\n",
       " [8, 0, 'Testing data/8\\\\3294.png'],\n",
       " [8, 2, 'Testing data/8\\\\3297.png'],\n",
       " [8, 6, 'Testing data/8\\\\3310.png'],\n",
       " [8, 2, 'Testing data/8\\\\3316.png'],\n",
       " [8, 2, 'Testing data/8\\\\3344.png'],\n",
       " [8, 2, 'Testing data/8\\\\3367.png'],\n",
       " [8, 0, 'Testing data/8\\\\3392.png'],\n",
       " [8, 0, 'Testing data/8\\\\3397.png'],\n",
       " [8, 6, 'Testing data/8\\\\3398.png'],\n",
       " [8, 0, 'Testing data/8\\\\3443.png'],\n",
       " [8, 0, 'Testing data/8\\\\3445.png'],\n",
       " [8, 6, 'Testing data/8\\\\3457.png'],\n",
       " [8, 0, 'Testing data/8\\\\3470.png'],\n",
       " [8, 6, 'Testing data/8\\\\3474.png'],\n",
       " [8, 6, 'Testing data/8\\\\3476.png'],\n",
       " [8, 2, 'Testing data/8\\\\3481.png'],\n",
       " [8, 0, 'Testing data/8\\\\3483.png'],\n",
       " [8, 2, 'Testing data/8\\\\3504.png'],\n",
       " [8, 0, 'Testing data/8\\\\3506.png'],\n",
       " [8, 2, 'Testing data/8\\\\3569.png'],\n",
       " [8, 6, 'Testing data/8\\\\3573.png'],\n",
       " [8, 0, 'Testing data/8\\\\3578.png'],\n",
       " [8, 4, 'Testing data/8\\\\3581.png'],\n",
       " [8, 2, 'Testing data/8\\\\3588.png'],\n",
       " [8, 2, 'Testing data/8\\\\3592.png'],\n",
       " [8, 2, 'Testing data/8\\\\3594.png'],\n",
       " [8, 2, 'Testing data/8\\\\3597.png'],\n",
       " [8, 2, 'Testing data/8\\\\3600.png'],\n",
       " [8, 2, 'Testing data/8\\\\3601.png'],\n",
       " [8, 4, 'Testing data/8\\\\3610.png'],\n",
       " [8, 0, 'Testing data/8\\\\3617.png'],\n",
       " [8, 0, 'Testing data/8\\\\3618.png'],\n",
       " [8, 2, 'Testing data/8\\\\3627.png'],\n",
       " [8, 0, 'Testing data/8\\\\3642.png'],\n",
       " [8, 4, 'Testing data/8\\\\3646.png'],\n",
       " [8, 6, 'Testing data/8\\\\3647.png'],\n",
       " [8, 6, 'Testing data/8\\\\3670.png'],\n",
       " [8, 6, 'Testing data/8\\\\3696.png'],\n",
       " [8, 0, 'Testing data/8\\\\3698.png'],\n",
       " [8, 6, 'Testing data/8\\\\3711.png'],\n",
       " [8, 0, 'Testing data/8\\\\3731.png'],\n",
       " [8, 2, 'Testing data/8\\\\3741.png'],\n",
       " [8, 2, 'Testing data/8\\\\3747.png'],\n",
       " [8, 6, 'Testing data/8\\\\3758.png'],\n",
       " [8, 2, 'Testing data/8\\\\3769.png'],\n",
       " [8, 2, 'Testing data/8\\\\3776.png'],\n",
       " [8, 0, 'Testing data/8\\\\3790.png'],\n",
       " [8, 4, 'Testing data/8\\\\3795.png'],\n",
       " [8, 0, 'Testing data/8\\\\3796.png'],\n",
       " [8, 0, 'Testing data/8\\\\3799.png'],\n",
       " [8, 2, 'Testing data/8\\\\3801.png'],\n",
       " [8, 0, 'Testing data/8\\\\3803.png'],\n",
       " [8, 0, 'Testing data/8\\\\3804.png'],\n",
       " [8, 0, 'Testing data/8\\\\3806.png'],\n",
       " [8, 0, 'Testing data/8\\\\3809.png'],\n",
       " [8, 6, 'Testing data/8\\\\3823.png'],\n",
       " [8, 0, 'Testing data/8\\\\3867.png'],\n",
       " [8, 2, 'Testing data/8\\\\3872.png'],\n",
       " [8, 0, 'Testing data/8\\\\3883.png'],\n",
       " [8, 2, 'Testing data/8\\\\3884.png'],\n",
       " [8, 2, 'Testing data/8\\\\3900.png'],\n",
       " [8, 2, 'Testing data/8\\\\3916.png'],\n",
       " [8, 0, 'Testing data/8\\\\3924.png'],\n",
       " [8, 6, 'Testing data/8\\\\3959.png'],\n",
       " [8, 6, 'Testing data/8\\\\3965.png'],\n",
       " [8, 2, 'Testing data/8\\\\3988.png'],\n",
       " [8, 0, 'Testing data/8\\\\3994.png']]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = list()\n",
    "network = train('img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Predict - Settings**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_PATH = 'Testing data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Predict**</font>\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    predict_o = []\n",
    "    filenames = []\n",
    "    wrong = []\n",
    "    correct = 0\n",
    "    for number in OUTPUTS:\n",
    "        for filename in glob.glob(TESTING_PATH + str(number) + '/*.png'):\n",
    "            base = os.path.splitext(os.path.basename(filename))[0]\n",
    "            data = loadImage(filename)\n",
    "            filenames.append(base)\n",
    "            \n",
    "            output = forward_prop(data[0])\n",
    "\n",
    "            val = [i for i in np.where(output == np.amax(output))]\n",
    "            ans = np.around(OUTPUTS[val[0][0]]).astype(int)\n",
    "            #print(val)\n",
    "            if ans == number:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong.append([number, ans, filename])\n",
    "            predict_o.append(ans)\n",
    "            \n",
    "    final = list()\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "        final.append({ filenames[i] : predict_o[i]})\n",
    "\n",
    "\n",
    "    with open('outputs.txt', 'w') as f:\n",
    "        for item in final:\n",
    "            f.write(\"%s\\n\" % str(item).replace('{', '').replace('}', '').replace(\"'\", '').replace(':', ''))\n",
    "            \n",
    "    print('correct : ' + str(correct) + ' (' + str((correct / len(filenames)) * 100) + ' %)')\n",
    "    print('wrong : ' + str(len(filenames) - correct) + ' (' + str(((len(filenames) - correct) / len(filenames)) * 100) + ' %)')\n",
    "    return wrong\n",
    "    \n",
    "def predict_one(data = []):\n",
    "    files = []\n",
    "    if data == []:\n",
    "        for number in OUTPUTS:\n",
    "            for filename in glob.glob(TESTING_PATH + str(number) + '/*.png'):\n",
    "                f = TESTING_PATH + str(number) + '/' + os.path.basename(filename)\n",
    "                files.append([number, f])\n",
    "        \n",
    "        input = random.choice(files)\n",
    "        filename = input[1]\n",
    "        correct = input[0]\n",
    "    else:\n",
    "        filename = data[2]\n",
    "        ans = data[1]\n",
    "        correct = data[0]\n",
    "    img, exp = loadImage(filename)\n",
    "\n",
    "    output = forward_prop(np.matrix(img))\n",
    "    \n",
    "    if data == []:\n",
    "        val = [i for i in np.where(output == np.amax(output))]\n",
    "        ans = np.around(OUTPUTS[val[0][0]]).astype(int)\n",
    "    \n",
    "    printImage(filename)\n",
    "    print('program output : ' + str(ans))\n",
    "    print('correct output : ' + str(correct))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct : 3822 (95.55 %)\n",
      "wrong : 178 (4.45 %)\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8EFCEC668>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 4\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8EFCEC208>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 8\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8ED9F0C18>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 8\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8F1E3AD68>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e68a909d5065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredict_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0miter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3233a008cde7>\u001b[0m in \u001b[0;36mpredict_one\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOUTPUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mprintImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'program output : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'correct output : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d03c52fca2cc>\u001b[0m in \u001b[0;36mprintImage\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#plt.imshow(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_training_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[1;34m(interval)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   2258\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2260\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2261\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrong = predict()\n",
    "iter = 0\n",
    "for w in wrong:\n",
    "    if iter > 10:\n",
    "        break\n",
    "    predict_one(w)\n",
    "    iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
