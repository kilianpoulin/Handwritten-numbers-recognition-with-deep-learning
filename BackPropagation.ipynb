{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "\n",
    "def loadImage(img_path, outputs = 0, number = 0):\n",
    "    pix = np.asarray(Image.open(img_path).convert('L'))\n",
    "    pix = (pix * (1 / 255)).reshape(784)\n",
    "    if outputs != 0:\n",
    "        for i in outputs:\n",
    "            if i == number:\n",
    "                pix = np.append(pix, 1)\n",
    "            else:\n",
    "                pix = np.append(pix, 0)\n",
    "    return pix\n",
    "\n",
    "def load_training_dataset(outputs, data_nb = 0):\n",
    "    dataset = []\n",
    "    path = 'Training data/'\n",
    "    \n",
    "    filenames = []\n",
    "    for o in outputs:\n",
    "        for filename in glob.glob(path + str(o) + '/*.png'): \n",
    "            base = os.path.basename(filename)\n",
    "            filenames.append([str(o) + '/' + base, o])\n",
    "    \n",
    "    random.shuffle(filenames)\n",
    "    if data_nb != 0:\n",
    "        filenames = filenames[:data_nb]\n",
    "        \n",
    "    for file in filenames:\n",
    "        dataset.append(loadImage(path + file[0], outputs, file[1]))\n",
    "    return dataset\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = []\n",
    "    filenames = []\n",
    "    for filename in glob.glob(path + '/*.png'): \n",
    "        dataset.append(loadImage(filename))\n",
    "        base = os.path.splitext(os.path.basename(filename))[0]\n",
    "        filenames.append(base)\n",
    "     \n",
    "    return len(dataset), filenames\n",
    "\n",
    "def load_testing_dataset(path):\n",
    "    dataset = []\n",
    "    filenames = []\n",
    "    \n",
    "    for filename in glob.glob(path + '/*.png'): \n",
    "        dataset.append(loadImage(filename))\n",
    "        base = os.path.splitext(os.path.basename(filename))[0]\n",
    "        filenames.append(base)\n",
    "        \n",
    "    return dataset, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from decimal import *\n",
    "\n",
    "getcontext().prec = 100\n",
    "\n",
    "def sigmoid(x):\n",
    "    return Decimal(1 / (1 + Decimal(np.exp(-x))))\n",
    "\n",
    "\n",
    "def forward_prop(network, inputs):\n",
    "    vect_sigmoid = np.vectorize(sigmoid)\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        new_inputs = []\n",
    "        \n",
    "        inputs = np.asarray([Decimal(s) for s in inputs])\n",
    "        act_sum = np.dot(layer[1]['w'], inputs)\n",
    "        layer[0]['a'] = vect_sigmoid(act_sum.astype(Decimal))\n",
    "            \n",
    "        layer[0]['a'] = np.asarray([Decimal(s) for s in layer[0]['a']])\n",
    "\n",
    "        new_inputs.append(layer[0]['a'])\n",
    "        inputs = new_inputs[0]\n",
    "    return inputs\n",
    "\n",
    "# Update network weights with error\n",
    "def update_weights(network, data, l_rate):\n",
    "    delta = list()\n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        \n",
    "        layer[3]['e'] = np.asarray([Decimal(i) for i in layer[3]['e']])\n",
    "        for neuron in range(len(layer[1]['w'])):\n",
    "            #n = list()\n",
    "            for b_neuron in range(len(layer[1]['w'][neuron])):\n",
    "                if i != 0:\n",
    "                    delta = Decimal(l_rate) * layer[3]['e'][neuron] * network[i - 1][0]['a'][b_neuron]\n",
    "                    #n.append(l_rate * layer[3]['e'][neuron] * network[i - 1][0]['a'][b_neuron])\n",
    "                else:\n",
    "                    delta = Decimal(l_rate) * layer[3]['e'][neuron] * data[b_neuron]\n",
    "                    #n.append(l_rate * layer[3]['e'][neuron] * data[b_neuron])\n",
    "                layer[1]['w'][neuron][b_neuron] = layer[1]['w'][neuron][b_neuron] + delta\n",
    "                \n",
    "\n",
    "        \n",
    "def backward_prop_error(network, expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = list()\n",
    "        \n",
    "        # case where it is not the output layer\n",
    "        if i != len(network)-1:\n",
    "            o_errors = network[i + 1][3]['e']\n",
    "            o_weights = network[i + 1][1]['w']\n",
    "            errors = np.dot(\n",
    "                np.dot(np.transpose(o_weights), o_errors),\n",
    "                np.dot(layer[0]['a'], Decimal(1) - layer[0]['a']))\n",
    "            layer[3]['e'] = errors\n",
    "        else:\n",
    "            errors = np.dot(np.transpose(expected) - layer[0]['a'], np.dot(layer[0]['a'], (1 - layer[0]['a'])))\n",
    "            layer[3]['e']  = errors\n",
    "            \n",
    "            \n",
    "def update_line(hl, new_data, iter):\n",
    "    hl.set_xdata(np.append(hl.get_xdata(), iter))\n",
    "    hl.set_ydata(np.append(hl.get_ydata(), new_data))\n",
    "    plt.draw()\n",
    "    \n",
    "\n",
    "def train_network(network, train, l_rate, nb_outputs, nb_iter):\n",
    "    err_plot, = plt.plot([], [])\n",
    "    plt.ylabel('error')\n",
    "    axes = plt.gca()\n",
    "    iter = 0\n",
    "    min_err = 2\n",
    "    for epoch in range(nb_iter):\n",
    "        error = 0\n",
    "        for data in train:\n",
    "            new_data = data[: len(data) - nb_outputs] \n",
    "            outputs = forward_prop(network, new_data)\n",
    "            # get last elements from data row (contains expected outputs)\n",
    "            expected = data[-nb_outputs:]\n",
    "            #print(outputs)\n",
    "            # expected = [0 for i in range(n_outputs - 1)]\n",
    "            # expected[row[-1]] = 1\n",
    "            #cost_function = 0.5 * sum([(expected[i]-outputs[i])**2 for i in range(len(expected))])\n",
    "            error += error_function(expected, outputs)\n",
    "            backward_prop_error(network, expected)\n",
    "            update_weights(network, data, l_rate)\n",
    "        \n",
    "        final_err = Decimal(error / len(train))\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, final_err))\n",
    "        if epoch == 0:\n",
    "            axes.set_xlim([0, nb_iter])\n",
    "            axes.set_ylim([0, float(error) + 0.1])\n",
    "            \n",
    "        update_line(err_plot, final_err, epoch)\n",
    "        \n",
    "        if error < min_err:\n",
    "            min_err = final_err\n",
    "        if error < 0.0001:\n",
    "            print('error : ' + str(final_err))\n",
    "            return network\n",
    "    print('error     : ' + str(final_err))\n",
    "    print('min error : ' + str(min_err))\n",
    "    return network\n",
    "    \n",
    "def error_function(expected, outputs):\n",
    "    return Decimal(1/len(outputs)) * Decimal(sum([(expected[i]-outputs[i])**2 for i in range(len(expected))]))\n",
    "\n",
    "def initialize_network(nb_inputs, nb_hidden, nb_hidden_layers, nb_outputs):\n",
    "    network = list()\n",
    "    w = []\n",
    "    \n",
    "    # additionnal hidden layers\n",
    "    for i in range(nb_hidden_layers):\n",
    "        neurons = [{ 'neurons': nb_hidden[i]}]\n",
    "        if i == 0:\n",
    "            w.append(np.random.rand(nb_hidden[i], nb_inputs) / 784) \n",
    "        else:\n",
    "            w.append(np.random.rand(nb_hidden[i], nb_hidden[i - 1]))\n",
    "        network.append(neurons)\n",
    "    \n",
    "    # output layer\n",
    "    neurons = [{ 'neurons': nb_outputs}]\n",
    "    w.append(np.random.rand(nb_outputs, nb_hidden[nb_hidden_layers - 1]))\n",
    "    network.append(neurons)\n",
    "    \n",
    "    for layer in network:\n",
    "              \n",
    "        w[0] = [[Decimal(i) for i in j] for j in w[0]]\n",
    "        wTmp = {'w': w[0]}\n",
    "        layer.append(wTmp)\n",
    "        w.pop(0)\n",
    "        \n",
    "        aTmp = { 'a': np.random.rand(layer[0]['neurons'])}\n",
    "        layer.append(aTmp)\n",
    "        \n",
    "        eTmp = { 'e': np.random.rand(layer[0]['neurons'])}\n",
    "        layer.append(eTmp)\n",
    "    return network\n",
    "  \n",
    "    \n",
    "# data_type => either 'img' or 'xor'\n",
    "# data_nb => number of data rows (entries)\n",
    "# nb_iter => number of iterations ot get to result\n",
    "# outputs => list of outputs (from 0 to 9 for img), not necessary for XOR\n",
    "# nb_hidden layer => number of hidden layers, 1 by default\n",
    "# nb_hidden => number of hidden neurons on each hidden layer ( 2 by default )\n",
    "\n",
    "# load input : load_testing_dataset(data_nb)\n",
    "def test(network, dataset, data_nb, categories = [], filenames = []):\n",
    "    outputs = list()\n",
    "    if data_nb == 1:\n",
    "        outputs = forward_propagate(network, dataset)\n",
    "    else:\n",
    "        for data in dataset:\n",
    "            outputs.append(forward_propagate(network, data))\n",
    "   \n",
    "    if categories != []:\n",
    "        for m in range(len(outputs)):\n",
    "            val = [i for i in np.where(outputs[m] == np.amax(outputs[m]))]\n",
    "            outputs[m] = categories[val[0][0]]\n",
    "    \n",
    "    results = outputs\n",
    "    \n",
    "    if filenames == []:\n",
    "        return results\n",
    "    else :\n",
    "        results = np.around(outputs).astype(int)\n",
    "        final = list()\n",
    "\n",
    "        for i in range(len(results)):\n",
    "            final.append({ filenames[i] : results[i]})\n",
    "            \n",
    "\n",
    "        with open('outputs.txt', 'w') as f:\n",
    "            for item in final:\n",
    "                f.write(\"%s\\n\" % str(item).replace('{', '').replace('}', '').replace(\"'\", '').replace(':', ''))\n",
    "        return final\n",
    "    \n",
    "\n",
    "def train(data_type, data_nb, nb_iter = 0, outputs = [], nb_hidden = [16], nb_hidden_layer = 1):\n",
    "\n",
    "    nb_outputs = 0\n",
    "    nb_inputs = 0\n",
    "    #for imagesTra\n",
    "    if data_type == 'img':\n",
    "        nb_inputs = 28 * 28\n",
    "        nb_outputs = len(outputs)\n",
    "        x = np.array(load_training_dataset(outputs, data_nb), dtype=np.dtype(Decimal))\n",
    "        x = [[ Decimal(i) for i in j] for j in x]\n",
    "    elif data_type == 'xor':\n",
    "        nb_outputs = 3\n",
    "        nb_inputs = 2\n",
    "        x = [[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]]\n",
    "    else:\n",
    "        return 'Wrong datatype (should be img or xor)'\n",
    "\n",
    "\n",
    "    network = initialize_network(nb_inputs, nb_hidden, nb_hidden_layer, nb_outputs)\n",
    "    return train_network(network, x, 1, nb_outputs, nb_iter)\n",
    "\n",
    "def retrain(data_type, data_nb, nb_iter = 0, outputs = []):\n",
    "\n",
    "    nb_outputs = 0\n",
    "    nb_inputs = 0\n",
    "    \n",
    "    #for images\n",
    "    if data_type == 'img':\n",
    "        nb_inputs = 28 * 28\n",
    "        nb_outputs = len(outputs)\n",
    "        x = np.array(load_training_dataset(outputs, data_nb), dtype=np.dtype(Decimal))\n",
    "        x = [[ Decimal(i) for i in j] for j in x]\n",
    "    elif data_type == 'xor':\n",
    "        nb_outputs = 3\n",
    "        nb_inputs = 2\n",
    "        x = [[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]]\n",
    "    else:\n",
    "        return 'Wrong datatype (should be img or xor)'\n",
    "\n",
    "\n",
    "    return train_network(network, x, 1, nb_outputs, nb_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">epoch=0, lrate=1.000, error=0.251\n",
      ">epoch=1, lrate=1.000, error=0.250\n",
      ">epoch=2, lrate=1.000, error=0.250\n",
      ">epoch=3, lrate=1.000, error=0.250\n",
      ">epoch=4, lrate=1.000, error=0.250\n",
      ">epoch=5, lrate=1.000, error=0.250\n",
      ">epoch=6, lrate=1.000, error=0.250\n",
      ">epoch=7, lrate=1.000, error=0.250\n"
     ]
    }
   ],
   "source": [
    "#network = train('xor', 4, 300, [], [16, 8], 2)\n",
    "#test(network, [[1,0], [1,1], [0,0], [0,1]], 4)\n",
    "\n",
    "network = train('img', 1000, 10, [0,1,3, 8, 9], [16, 2], 1)\n",
    "#network = retrain('img', 5000, 20, [0,1,3, 8, 9])\n",
    "dataset, filenames = load_testing_dataset('Testing data')\n",
    "test(network, dataset, 9, [0,1, 3, 8, 9], filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
