{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network architecture**</font>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Variable</th>\n",
    "        <th>Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>OUTPUTS</td>\n",
    "        <td><i>array containing all possible outputs</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_HIDDEN_LAYERS</td>\n",
    "        <td><i>integer</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_HIDDEN_NODES</td>\n",
    "        <td><i>array containing the number of hidden nodes for each hidden layer (from the first one to the last one)</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_INPUTS </td>\n",
    "        <td><i>number of nodes on the input layer</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_EPOCH </td>\n",
    "        <td><i>number of times the training data set will be used entirely to train the network</i></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OUTPUTS = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "OUTPUTS = [0, 2, 4, 6, 8]\n",
    "NB_OUTPUTS = len(OUTPUTS)\n",
    "NB_HIDDEN_LAYERS = 1\n",
    "NB_HIDDEN_NODES = [100]\n",
    "NB_INPUTS = 784\n",
    "NB_EPOCH = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural Network Training settings**</font>\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th style=\"text-align: center\">Variable</th>\n",
    "        <th style=\"text-align: center\">Description</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Training dataset</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>NB_DATA</td>\n",
    "        <td style=\"text-align: left\"><i>integer - Number of data used in the dataset</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>TRAINING PATH</td>\n",
    "        <td style=\"text-align: left\"><i>string - relative or full path of the training dataset folder</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>DATA_TYPE</td>\n",
    "        <td style=\"text-align: left\"><i>string - either 'img' or 'xor', depends on type of input data</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Learning rate</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L_RATE</td>\n",
    "        <td style=\"text-align: left\"><i>float - Initial learning rate for the first epoch</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>L_RATE_DESC</td>\n",
    "        <td style=\"text-align: left\"><i>float - variation of the learning rate : L_RATE * L_RATE_DESC at the end of each epoch. If no variation then L_RATE_DESC = 1.0</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Weights</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align: center\">WEIGHTS_LOW_BOUND</td>\n",
    "        <td style=\"text-align: left\"><i>float or integer - Weights are initialized randomly in a range of values</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>WEIGHTS_HIGH_BOUND</td>\n",
    "        <td style=\"text-align: left\"><i>float or integer - Weights are initialized randomly in a range of values</i></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td colspan=\"2\" style=\"text-align: center\"><font size=\"4\">Error</font></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>ERR_THRESHOLD</td>\n",
    "        <td style=\"text-align: left\"><i>Minimum limit for the error value. If reached, the network can stop learning. Accuracy is good enough</i></td>\n",
    "    </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DATA = 16000\n",
    "TRAINING_PATH = 'Training data/'\n",
    "DATA_TYPE = 'img'\n",
    "\n",
    "# LEARNING RATE\n",
    "L_RATE = 0.01\n",
    "L_RATE_DESC = 1.0\n",
    "\n",
    "# INITIAL WEIGHTS RANGE\n",
    "WEIGHTS_LOW_BOUND = -0.5\n",
    "WEIGHTS_HIGH_BOUND = 0.5\n",
    "\n",
    "# ERROR THRESHOLD\n",
    "ERR_THRESHOLD = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Load dataset**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "import glob\n",
    "import os\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def loadImage(img_path, number = 0):\n",
    "    pix = np.asarray(Image.open(img_path).convert('L'))\n",
    "    pix = ((pix * (1 / 2550) - 0.05)).reshape(784)\n",
    "    expected = []\n",
    "    if OUTPUTS != []:\n",
    "        for i in OUTPUTS:\n",
    "            if i == number:\n",
    "                expected = np.append(expected, 1)\n",
    "            else:\n",
    "                expected = np.append(expected, 0)\n",
    "    return pix, expected\n",
    "\n",
    "def printImage(img_path):\n",
    "    plt.close()\n",
    "    plt.figure()\n",
    "    img = Image.open(img_path)\n",
    "    img = img.resize((12, 12), Image.ANTIALIAS)\n",
    "    print(img)\n",
    "    #plt.imshow(img)\n",
    "    plt.pause(1)\n",
    "    \n",
    "def load_training_dataset():\n",
    "    dataset = []\n",
    "    expected = []\n",
    "    \n",
    "    filenames = []\n",
    "    for o in OUTPUTS:\n",
    "        for filename in glob.glob(TRAINING_PATH + str(o) + '/*.png'): \n",
    "            base = os.path.basename(filename)\n",
    "            filenames.append([str(o) + '/' + base, o])\n",
    "    \n",
    "    random.shuffle(filenames)\n",
    "    if NB_DATA != 0:\n",
    "        filenames = filenames[:NB_DATA]\n",
    "        \n",
    "    for file in filenames:\n",
    "        img, exp = loadImage(TRAINING_PATH + file[0], file[1])\n",
    "        dataset.append(img)\n",
    "        expected.append(exp)\n",
    "        \n",
    "    return dataset, expected\n",
    "\n",
    "def load_dataset(path):\n",
    "    dataset = []\n",
    "    filenames = []\n",
    "    for filename in glob.glob(path + '/*.png'): \n",
    "        dataset.append(loadImage(filename))\n",
    "        base = os.path.splitext(os.path.basename(filename))[0]\n",
    "        filenames.append(base)\n",
    "     \n",
    "    return len(dataset), filenames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Initialization**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_network():\n",
    "    \n",
    "    global network\n",
    "    w = []\n",
    "    \n",
    "    # additionnal hidden layers\n",
    "    for i in range(NB_HIDDEN_LAYERS):\n",
    "        neurons = [{ 'neurons': NB_HIDDEN_NODES[i]}]\n",
    "        if i == 0:\n",
    "            w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_HIDDEN_NODES[i], NB_INPUTS)))\n",
    "        else:\n",
    "            w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_HIDDEN_NODES[i], NB_HIDDEN_NODES[i - 1])))\n",
    "\n",
    "        network.append(neurons)\n",
    "    \n",
    "    # output layer\n",
    "    neurons = [{ 'neurons': NB_OUTPUTS}]\n",
    "    w.append(np.random.uniform(low=WEIGHTS_LOW_BOUND, high=WEIGHTS_HIGH_BOUND, size=(NB_OUTPUTS, NB_HIDDEN_NODES[NB_HIDDEN_LAYERS - 1])))\n",
    "    network.append(neurons)\n",
    "    \n",
    "    for layer in network:\n",
    "              \n",
    "        wTmp = {'w': w[0]}\n",
    "        layer.append(wTmp)\n",
    "        w.pop(0)\n",
    "        \n",
    "        aTmp = { 'a': np.matrix(np.random.rand(layer[0]['neurons']))}\n",
    "        layer.append(aTmp)\n",
    "        \n",
    "        eTmp = { 'e': np.matrix(np.random.rand(layer[0]['neurons']))}\n",
    "        layer.append(eTmp)\n",
    "        \n",
    "    print('end initializing network')\n",
    "    return network\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Deep Learning - Forward Propagation**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    " \n",
    "def forward_prop(inputs):\n",
    "    global network\n",
    "    vect_sigmoid = np.vectorize(sigmoid)\n",
    "    \n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        new_inputs = []\n",
    "        \n",
    "        if (inputs.shape)[0] == 1 :\n",
    "            layer[0]['a'] = vect_sigmoid(np.dot(layer[1]['w'], inputs.T))\n",
    "        else:\n",
    "            layer[0]['a'] = vect_sigmoid(np.dot(layer[1]['w'], inputs))\n",
    "\n",
    "        new_inputs.append(layer[0]['a'])\n",
    "        inputs = new_inputs[0]\n",
    "    return np.matrix(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Deep Learning - Backpropagation error**</font>\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update network weights with error\n",
    "def update_weights(data):\n",
    "    delta = []\n",
    "    global L_RATE\n",
    "    \n",
    "    for i in range(len(network)):\n",
    "        layer = network[i]\n",
    "        \n",
    "        if i != 0:\n",
    "            delta = np.multiply((layer[3]['e'] * L_RATE).T, network[i - 1][0]['a'])\n",
    "        else:\n",
    "            delta = np.multiply((layer[3]['e'] * L_RATE).T, data)\n",
    "        layer[1]['w'] = layer[1]['w'] + delta.T\n",
    "        \n",
    "def backward_prop_error(expected):\n",
    "    for i in reversed(range(len(network))):\n",
    "        layer = network[i]\n",
    "        errors = []\n",
    "        \n",
    "        # case where it is not the output layer\n",
    "        if i != len(network)-1:\n",
    "            o_errors = network[i + 1][3]['e']\n",
    "            o_weights = network[i + 1][1]['w']\n",
    "            \n",
    "            errors = np.dot(\n",
    "                np.dot(o_weights.T, o_errors),\n",
    "                np.dot((layer[0]['a'].T), 1 - layer[0]['a']))\n",
    "            \n",
    "            layer[3]['e'] = errors\n",
    "        else:\n",
    "            errors = np.dot(expected.T - layer[0]['a'], np.dot((layer[0]['a']).T, (1 - layer[0]['a'])))\n",
    "            layer[3]['e']  = errors\n",
    "            \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Training**</font>\n",
    "<br><br>\n",
    "\n",
    "* **train_network()**\n",
    "<br>\n",
    "Executes the whole training process (forward propagation + backward propagation error + updating weights) for each epoch\n",
    "<br><br>\n",
    "\n",
    "* **error_function**(expected outputs: array of integers, outputs of the program: array of floats)\n",
    "<br>\n",
    "Calculates the average error for each output when processing element thru the neural network\n",
    "<br><br>\n",
    "\n",
    "* **update_line**(plot: plt, new error value: integer, iter: integer)\n",
    "<br>\n",
    "Adds the newly calculated error to the graph showing evolution of the error function values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_function(expected, outputs):\n",
    "   # return (1/len(outputs)) * sum(np.square(expected - outputs))\n",
    "    return sum(np.square(expected - outputs))\n",
    "\n",
    "def update_line(hl, new_data, iter):\n",
    "    hl.set_xdata(np.append(hl.get_xdata(), iter))\n",
    "    hl.set_ydata(np.append(hl.get_ydata(), new_data))\n",
    "    plt.draw()\n",
    "\n",
    "\n",
    "def train_network():\n",
    "    \n",
    "    global network\n",
    "    global L_RATE\n",
    "    global L_RATE_DESC\n",
    "    expected = []\n",
    "    dataset = []\n",
    "    \n",
    "    \n",
    "    # ------ Initialization part -------\n",
    "    \n",
    "    if DATA_TYPE == 'img':\n",
    "        if dataset == []:\n",
    "            dataset, exp = load_training_dataset()\n",
    "            x = np.matrix(dataset)\n",
    "            expected = np.matrix(exp)\n",
    "        else:\n",
    "            x = dataset\n",
    "    elif DATE_TYPE == 'xor':\n",
    "        x = np.matrix([[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]])\n",
    "    else:\n",
    "        return 'Wrong datatype (should be iprintpmg or xor)'\n",
    "\n",
    "    network = initialize_network()\n",
    "    \n",
    "    \n",
    "    # --------- Training part ----------\n",
    "    \n",
    "    err_plot, = plt.plot([], [])\n",
    "    plt.ylabel('error')\n",
    "    axes = plt.gca()\n",
    "    iter = 0\n",
    "    \n",
    "    for epoch in range(NB_EPOCH):\n",
    "        error = 0\n",
    "        iter = 0\n",
    "        for data in x:\n",
    "            new_data = data.T\n",
    "            outputs = forward_prop(new_data)\n",
    "            \n",
    "            error += error_function(expected[iter].T, outputs)\n",
    "            \n",
    "            backward_prop_error(expected[iter])\n",
    "            update_weights(new_data)\n",
    "            \n",
    "            iter += 1\n",
    "            \n",
    "        final_err = error / len(x)\n",
    "        print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, L_RATE, final_err))\n",
    "        \n",
    "        L_RATE *= L_RATE_DESC\n",
    "        if epoch == 0:\n",
    "            axes.set_xlim([0, NB_EPOCH - 1])\n",
    "            axes.set_ylim([0, float(final_err) + 0.1])\n",
    "            \n",
    "        update_line(err_plot, final_err, epoch)\n",
    "        \n",
    "        if error < ERR_THRESHOLD:\n",
    "            print('error : ' + str(final_err))\n",
    "            return network\n",
    "    print('error     : ' + str(final_err))\n",
    "    return network\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Neural network - Additional training**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrain(data_type, data_nb, nb_iter = 0, outputs = []):\n",
    "\n",
    "    nb_outputs = 0\n",
    "    nb_inputs = 0\n",
    "    \n",
    "    #for images\n",
    "    if data_type == 'img':\n",
    "        nb_inputs = 28 * 28\n",
    "        \n",
    "        \n",
    "        \n",
    "        nb_outputs = len(outputs)\n",
    "        x = np.array(load_training_dataset(outputs, data_nb), dtype=np.dtype(Decimal))\n",
    "        x = [[ Decimal(i) for i in j] for j in x]\n",
    "    elif data_type == 'xor':\n",
    "        nb_outputs = 3\n",
    "        nb_inputs = 2\n",
    "        x = [[1, 0, 1, 1, 1], [1, 1, 0, 1, 0], [0, 0, 1, 0, 0], [0, 1, 0, 0, 1]]\n",
    "    else:\n",
    "        return 'Wrong datatype (should be img or xor)'\n",
    "\n",
    "\n",
    "    return train_network(network, x, 1, nb_outputs, nb_iter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Execution - Training**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "end initializing network\n",
      ">epoch=0, lrate=0.010, error=0.166\n",
      ">epoch=1, lrate=0.010, error=0.106\n",
      ">epoch=2, lrate=0.010, error=0.094\n",
      ">epoch=3, lrate=0.010, error=0.088\n"
     ]
    }
   ],
   "source": [
    "network = list()\n",
    "network = train_network()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Predict - Settings**</font>\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTING_PATH = 'Testing data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"6\">**Predict**</font>\n",
    "<br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict():\n",
    "    predict_o = []\n",
    "    filenames = []\n",
    "    wrong = []\n",
    "    correct = 0\n",
    "    for number in OUTPUTS:\n",
    "        for filename in glob.glob(TESTING_PATH + str(number) + '/*.png'):\n",
    "            base = os.path.splitext(os.path.basename(filename))[0]\n",
    "            data = loadImage(filename)\n",
    "            filenames.append(base)\n",
    "            \n",
    "            output = forward_prop(data[0])\n",
    "\n",
    "            val = [i for i in np.where(output == np.amax(output))]\n",
    "            ans = np.around(OUTPUTS[val[0][0]]).astype(int)\n",
    "            #print(val)\n",
    "            if ans == number:\n",
    "                correct += 1\n",
    "            else:\n",
    "                wrong.append([number, ans, filename])\n",
    "            predict_o.append(ans)\n",
    "            \n",
    "    final = list()\n",
    "\n",
    "    for i in range(len(filenames)):\n",
    "        final.append({ filenames[i] : predict_o[i]})\n",
    "\n",
    "\n",
    "    with open('outputs.txt', 'w') as f:\n",
    "        for item in final:\n",
    "            f.write(\"%s\\n\" % str(item).replace('{', '').replace('}', '').replace(\"'\", '').replace(':', ''))\n",
    "            \n",
    "    print('correct : ' + str(correct) + ' (' + str((correct / len(filenames)) * 100) + ' %)')\n",
    "    print('wrong : ' + str(len(filenames) - correct) + ' (' + str(((len(filenames) - correct) / len(filenames)) * 100) + ' %)')\n",
    "    return wrong\n",
    "    \n",
    "def predict_one(data = []):\n",
    "    files = []\n",
    "    if data == []:\n",
    "        for number in OUTPUTS:\n",
    "            for filename in glob.glob(TESTING_PATH + str(number) + '/*.png'):\n",
    "                f = TESTING_PATH + str(number) + '/' + os.path.basename(filename)\n",
    "                files.append([number, f])\n",
    "        \n",
    "        input = random.choice(files)\n",
    "        filename = input[1]\n",
    "        correct = input[0]\n",
    "    else:\n",
    "        filename = data[2]\n",
    "        ans = data[1]\n",
    "        correct = data[0]\n",
    "    img, exp = loadImage(filename)\n",
    "\n",
    "    output = forward_prop(np.matrix(img))\n",
    "    \n",
    "    if data == []:\n",
    "        val = [i for i in np.where(output == np.amax(output))]\n",
    "        ans = np.around(OUTPUTS[val[0][0]]).astype(int)\n",
    "    \n",
    "    printImage(filename)\n",
    "    print('program output : ' + str(ans))\n",
    "    print('correct output : ' + str(correct))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_one()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct : 3822 (95.55 %)\n",
      "wrong : 178 (4.45 %)\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8EFCEC668>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 4\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8EFCEC208>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 8\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8ED9F0C18>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "program output : 8\n",
      "correct output : 0\n",
      "<PIL.Image.Image image mode=L size=12x12 at 0x1A8F1E3AD68>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-e68a909d5065>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0miter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mpredict_one\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0miter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-3233a008cde7>\u001b[0m in \u001b[0;36mpredict_one\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mans\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maround\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOUTPUTS\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m     \u001b[0mprintImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'program output : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mans\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'correct output : '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrect\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-18-d03c52fca2cc>\u001b[0m in \u001b[0;36mprintImage\u001b[1;34m(img_path)\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;31m#plt.imshow(img)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpause\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mload_training_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mpause\u001b[1;34m(interval)\u001b[0m\n\u001b[0;32m    302\u001b[0m             \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    303\u001b[0m         \u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 304\u001b[1;33m         \u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    305\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m         \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   2258\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_looping\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtimestep\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2259\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_events\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2260\u001b[1;33m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimestep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2261\u001b[0m             \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2262\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "wrong = predict()\n",
    "iter = 0\n",
    "for w in wrong:\n",
    "    if iter > 10:\n",
    "        break\n",
    "    predict_one(w)\n",
    "    iter += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
